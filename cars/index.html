<!doctype html>
<html lang="en">
 <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>REINFORCEjs: WaterWorld demo</title>
  <meta name="description" content="">
  <meta name="author" content="">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

   <!-- jquery and jqueryui -->
  <script src="node_modules/jquery/dist/jquery.min.js"></script>
  <link href="../external/jquery-ui.min.css" rel="stylesheet">
  <script src="../external/jquery-ui.min.js"></script>

  <!-- bootstrap -->
  <script src="node_modules/bootstrap/dist/js/bootstrap.min.js"></script>
  <link href="node_modules/bootstrap/dist/css/bootstrap.min.css" rel="stylesheet">

  <!-- d3js -->
  <script type="text/javascript" src="../external/d3.min.js"></script>

  <!-- markdown -->
  <script type="text/javascript" src="../external/marked.js"></script>
  <script type="text/javascript" src="../external/highlight.pack.js"></script>
  <link rel="stylesheet" href="../external/highlight_default.css">
  <script>hljs.initHighlightingOnLoad();</script>

  <!-- mathjax: nvm now loaded dynamically
  <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  -->

  <!-- rljs -->
  <script type="text/javascript" src="../lib/rl.js"></script>

  <!-- flotjs -->
  <script src="../external/jquery.flot.min.js"></script>

  <!-- environment dynamics -->
  <script src="environment.js"></script>

  <style>
  #wrap {
    width:800px;
    margin-left: auto;
    margin-right: auto;
  }
  h2 {
    text-align: center;
  }
  body {
    font-family: Arial, "Helvetica Neue", Helvetica, sans-serif;
  }
  canvas {
    border: 1px solid black;
  }
  </style>

     <script src="interaction.js"></script>
  <style type="text/css">
      canvas { border: 1px solid white; }
    </style>

 </head>
 <body onload="start();">

  <a href="https://github.com/karpathy/reinforcejs"><img style="position: absolute; top: 0; right: 0; border: 0;" src="https://camo.githubusercontent.com/38ef81f8aca64bb9a64448d0d70f1308ef5341ab/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6769746875622f726962626f6e732f666f726b6d655f72696768745f6461726b626c75655f3132313632312e706e67" alt="Fork me on GitHub" data-canonical-src="https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png"></a>
  
   <div id="wrap">


   <div id="mynav" style="border-bottom:1px solid #999; padding-bottom: 10px; margin-bottom:50px;">
    <div>
      <img src="loop.svg" style="width:50px;height:50px;float:left;">
      <h1 style="font-size:50px;">REINFORCE<span style="color:#058;">js</span></h1>
    </div>
    <ul class="nav nav-pills">
      <li role="presentation"><a href="index.html">About</a></li>
      <li role="presentation"><a href="gridworld_dp.html">GridWorld: DP</a></li>
      <li role="presentation"><a href="gridworld_td.html">GridWorld: TD</a></li>
      <li role="presentation"><a href="puckworld.html">PuckWorld: DQN</a></li>
      <li role="presentation" class="active"><a href="waterworld.html">WaterWorld: DQN</a></li>
    </ul>
   </div>

<textarea id="agentspec" style="width:100%;height:250px;">
// agent parameter spec to play with (this gets eval()'d on Agent reset)
var spec = {}
spec.update = 'qlearn'; // qlearn | sarsa
spec.gamma = 0.9; // discount factor, [0, 1)
spec.epsilon = 0.2; // initial epsilon for epsilon-greedy policy, [0, 1)
spec.alpha = 0.005; // value function learning rate
spec.experience_add_every = 5; // number of time steps before we add another experience to replay memory
spec.experience_size = 10000; // size of experience
spec.learning_steps_per_iteration = 5;
spec.tderror_clamp = 1.0; // for robustness
spec.num_hidden_units = 200 // number of neurons in hidden layer
</textarea>

<div style="text-align:center;">
<button class="btn btn-danger" onclick="resetAgent()" style="width:150px;height:50px;margin-bottom:5px;">Reinit agent</button>
<button class="btn btn-success" onclick="goveryfast()" style="width:150px;height:50px;margin-bottom:5px;">Go very fast</button>
<button class="btn btn-success" onclick="gofast()" style="width:150px;height:50px;margin-bottom:5px;">Go fast</button>
<button class="btn btn-success" onclick="gonormal()" style="width:150px;height:50px;margin-bottom:5px;">Go normal</button>
<button class="btn btn-success" onclick="goslow()" style="width:150px;height:50px;margin-bottom:5px;">Go slow</button>
<button class="btn btn-danger" onclick="toggleAgentView()" style="width:150px;height:50px;margin-bottom:5px;">Toggle Agent View</button>
<button class="btn btn-danger" onclick="enableHuman()" style="width:150px;height:50px;margin-bottom:5px;">Start playing (use arrow keys)</button>

<canvas id="canvas" width="700" height="200"></canvas>
</div>

   <div id="apples_and_poison"></div>

   <div id="brain_info_div"></div>

<button class="btn btn-primary" onclick="loadAgent()" style="width:200px;height:35px;margin-bottom:5px;margin-right:20px;">Load a Pretrained Agent</button>

<br>
Exploration epsilon: <span id="eps">0.15</span> <div id="slider"></div>

<br>

<div id="expi"></div>
<div id="tde"></div>

<div id="flotreward" style="width:800px; height: 400px;"></div>

<textarea id="mysterybox" style="width:100%;display:none;">mystery text box</textarea>


<div id="exp" class="md">

### Setup

This is another Deep Q Learning demo with a more realistic and larger setup:

- The **state space** is even larger and continuous: The agent has 30 eye sensors pointing in all directions and in each direction is observes 5 variables: the range, the type of sensed object (green, red), and the velocity of the sensed object. The agent's proprioception includes two additional sensors for its own speed in both x and y directions. This is a total of 152-dimensional state space.
- There are 4 **actions** available to the agent: To apply thrusters to the left, right, up and down. This gives the agent control over its velocity.
- The **dynamics** integrate the velocity of the agent to change its position. The green and red targets bounce around.
- The **reward** awarded to the agent is +1 for making contact with any red target (these are apples) and -1 for making contact with any green target (this is poison).

The optimal strategy of the agent is to cruise around, run away from green targets and eat red targets. What's interesting about this demo is that the state space is so high-dimensional, and also that the sensed variables are agent-relative. They're not just toy x,y coordinates of some fixed number of targets as in previous demo.

</div>

<br><br><br><br>
   </div>
 </body>
</html>
